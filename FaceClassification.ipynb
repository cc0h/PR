{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T15:50:16.487667Z",
     "start_time": "2025-01-07T15:50:16.472708Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 自定义数据集类\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, data_file, raw_data_dir, transform=None):\n",
    "        self.data_file = data_file\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self.transform = transform\n",
    "        self.samples = self._load_samples()\n",
    "\n",
    "    def _load_samples(self):\n",
    "        samples = []\n",
    "        with open(self.data_file, 'r') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:\n",
    "                    print(f\"Skipping incomplete line {line_number}: {line}\")\n",
    "                    continue  # 跳过不完整或错误的数据行\n",
    "\n",
    "                try:\n",
    "                    image_id = parts[0]\n",
    "                    sex = parts[2].strip('()')\n",
    "                    age = parts[4].strip('()')\n",
    "                    race = parts[6].strip('()')\n",
    "                    face = parts[8].strip('()')\n",
    "                    samples.append((image_id, sex, age, race, face))\n",
    "                except IndexError as e:\n",
    "                    print(f\"Skipping malformed line {line_number} due to error: {e}\\nLine content: {line}\")\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, sex, age, race, face = self.samples[idx]\n",
    "        image_path = os.path.join(self.raw_data_dir, image_id)\n",
    "\n",
    "        file_size_kb = os.path.getsize(image_path) / 1024\n",
    "\n",
    "        if file_size_kb < 20:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                img = Image.fromarray(np.reshape(np.frombuffer(f.read(), dtype=np.uint8), (128, 128)))\n",
    "        else:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                img = Image.fromarray(np.reshape(np.frombuffer(f.read(), dtype=np.uint8), (512, 512)))\n",
    "                img = img.resize((512, 512))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 将类别标签转换为整数\n",
    "        sex_label = {'male': 0, 'female': 1}.get(sex, -1)\n",
    "        age_label = {'child': 0, 'teen': 1, 'adult': 2, 'senior': 3}.get(age, -1)\n",
    "        race_label = {'white': 0, 'yellow': 1, 'black': 2, 'hispanic': 3, 'asian': 4, 'other': 5}.get(race, -1)\n",
    "        face_label = {'smiling': 0, 'serious': 1, 'funny': 2}.get(face, -1)\n",
    "\n",
    "        labels = [sex_label, age_label, race_label, face_label]\n",
    "        if any(label == -1 for label in labels):\n",
    "            print(f\"Invalid label in sample: {self.samples[idx]}\")\n",
    "            raise ValueError(f\"Invalid label in sample: {self.samples[idx]}\")\n",
    "\n",
    "        return img, torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "# 数据变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = FaceDataset(data_file='face/faceDR', raw_data_dir='face/rawdata', transform=transform)\n",
    "test_dataset = FaceDataset(data_file='face/faceDS', raw_data_dir='face/rawdata', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping incomplete line 6:  1228 (_missing descriptor)\n",
      "\n",
      "Skipping incomplete line 10:  1232 (_missing descriptor)\n",
      "\n",
      "Skipping incomplete line 586:  1808 (_missing descriptor)\n",
      "\n",
      "Skipping incomplete line 834:  4056 (_missing descriptor)\n",
      "\n",
      "Skipping incomplete line 913:  4135 (_missing descriptor)\n",
      "\n",
      "Skipping incomplete line 914:  4136 (_missing descriptor)\n",
      "\n",
      "Skipping incomplete line 1782:  5004 (_missing descriptor)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:51:57.126434Z",
     "start_time": "2025-01-07T15:50:21.307283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义卷积神经网络模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)  # 性别\n",
    "        self.fc3 = nn.Linear(256, 4)  # 年龄\n",
    "        self.fc4 = nn.Linear(256, 6)  # 种族\n",
    "        self.fc5 = nn.Linear(256, 3)  # 表情\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        sex_output = self.fc2(x)\n",
    "        age_output = self.fc3(x)\n",
    "        race_output = self.fc4(x)\n",
    "        face_output = self.fc5(x)\n",
    "        return sex_output, age_output, race_output, face_output\n",
    "\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        sex_outputs, age_outputs, race_outputs, face_outputs = model(images)\n",
    "        loss = criterion(sex_outputs, labels[:, 0]) + \\\n",
    "               criterion(age_outputs, labels[:, 1]) + \\\n",
    "               criterion(race_outputs, labels[:, 2]) + \\\n",
    "               criterion(face_outputs, labels[:, 3])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "# 评估模型\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        sex_outputs, age_outputs, race_outputs, face_outputs = model(images)\n",
    "        _, predicted_sex = torch.max(sex_outputs, 1)\n",
    "        _, predicted_age = torch.max(age_outputs, 1)\n",
    "        _, predicted_race = torch.max(race_outputs, 1)\n",
    "        _, predicted_face = torch.max(face_outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += ((predicted_sex == labels[:, 0]).sum().item() +\n",
    "                    (predicted_age == labels[:, 1]).sum().item() +\n",
    "                    (predicted_race == labels[:, 2]).sum().item() +\n",
    "                    (predicted_face == labels[:, 3]).sum().item()) / 4\n",
    "\n",
    "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')"
   ],
   "id": "9f982989cd1e017a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.7201\n",
      "Epoch [2/10], Loss: 2.1257\n",
      "Epoch [3/10], Loss: 1.7388\n",
      "Epoch [4/10], Loss: 1.4487\n",
      "Epoch [5/10], Loss: 1.2453\n",
      "Epoch [6/10], Loss: 1.0505\n",
      "Epoch [7/10], Loss: 0.9126\n",
      "Epoch [8/10], Loss: 0.7396\n",
      "Epoch [9/10], Loss: 0.6126\n",
      "Epoch [10/10], Loss: 0.5397\n",
      "Accuracy of the model on the test images: 82.57%\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
